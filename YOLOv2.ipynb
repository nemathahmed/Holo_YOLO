{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 15:44:31.175668 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "W0620 15:44:31.183669 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "W0620 15:44:31.184668 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "W0620 15:44:31.185668 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "W0620 15:44:31.186669 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from darkflow.net.build import TFNet\n",
    "\n",
    "import argparse\n",
    "import socket\n",
    "import sys\n",
    "import binascii\n",
    "import struct\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 15:44:41.951033 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\build.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0620 15:44:41.954032 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\ops\\baseop.py:70: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0620 15:44:41.956040 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\ops\\baseop.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0620 15:44:41.968029 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\ops\\baseop.py:84: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0620 15:44:42.016028 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\ops\\simple.py:106: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.02600550651550293s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 15:44:45.974028 17404 deprecation.py:506] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\ops\\convolution.py:28: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "ksizes is deprecated, use sizes instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 15:44:46.920028 17404 deprecation_wrapper.py:119] From c:\\Users\\BME-4\\Anaconda3\\envs\\cv\\lib\\site-packages\\darkflow\\net\\build.py:132: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 1.0 usage\n",
      "Finished in 15.463421821594238s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options = {\"model\": \"cfg/yolo.cfg\", \n",
    "           \"load\": \"bin/yolo.weights\", \n",
    "           \"threshold\": 0.1, \n",
    "           \"gpu\": 1.0}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxing(original_img, predictions):\n",
    "    newImage = np.copy(original_img)\n",
    "\n",
    "    for result in predictions:\n",
    "        top_x = result['topleft']['x']\n",
    "        top_y = result['topleft']['y']\n",
    "\n",
    "        btm_x = result['bottomright']['x']\n",
    "        btm_y = result['bottomright']['y']\n",
    "\n",
    "        confidence = result['confidence']\n",
    "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
    "\n",
    "        if confidence > 0.3:\n",
    "            newImage = cv2.rectangle(newImage, (top_x, top_y), (btm_x, btm_y), (255,0,0), 3)\n",
    "            newImage = cv2.putText(newImage, label, (top_x, top_y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL , 0.8, (0, 230, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "    return newImage\n",
    "\n",
    "#_, ax = plt.subplots(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 700, 3)\n",
      "(406, 700, 3)\n",
      "(406, 700, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'person',\n",
       "  'confidence': 0.10301071,\n",
       "  'topleft': {'x': 307, 'y': 43},\n",
       "  'bottomright': {'x': 325, 'y': 71}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.44894347,\n",
       "  'topleft': {'x': 372, 'y': 3},\n",
       "  'bottomright': {'x': 423, 'y': 116}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.29144457,\n",
       "  'topleft': {'x': 407, 'y': 4},\n",
       "  'bottomright': {'x': 441, 'y': 103}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.17737837,\n",
       "  'topleft': {'x': 147, 'y': 2},\n",
       "  'bottomright': {'x': 237, 'y': 151}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.12745857,\n",
       "  'topleft': {'x': 228, 'y': 48},\n",
       "  'bottomright': {'x': 264, 'y': 110}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.6459309,\n",
       "  'topleft': {'x': 244, 'y': 46},\n",
       "  'bottomright': {'x': 280, 'y': 112}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.19171444,\n",
       "  'topleft': {'x': 327, 'y': 44},\n",
       "  'bottomright': {'x': 354, 'y': 109}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.12657483,\n",
       "  'topleft': {'x': 366, 'y': 32},\n",
       "  'bottomright': {'x': 400, 'y': 113}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.26815253,\n",
       "  'topleft': {'x': 6, 'y': 8},\n",
       "  'bottomright': {'x': 93, 'y': 190}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.4067667,\n",
       "  'topleft': {'x': 296, 'y': 55},\n",
       "  'bottomright': {'x': 333, 'y': 139}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.31901538,\n",
       "  'topleft': {'x': 17, 'y': 11},\n",
       "  'bottomright': {'x': 240, 'y': 350}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.24832135,\n",
       "  'topleft': {'x': 648, 'y': 86},\n",
       "  'bottomright': {'x': 697, 'y': 274}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.633512,\n",
       "  'topleft': {'x': 364, 'y': 24},\n",
       "  'bottomright': {'x': 576, 'y': 405}},\n",
       " {'label': 'person',\n",
       "  'confidence': 0.38656864,\n",
       "  'topleft': {'x': 554, 'y': 160},\n",
       "  'bottomright': {'x': 659, 'y': 296}},\n",
       " {'label': 'chair',\n",
       "  'confidence': 0.31190586,\n",
       "  'topleft': {'x': 242, 'y': 72},\n",
       "  'bottomright': {'x': 280, 'y': 112}},\n",
       " {'label': 'bird',\n",
       "  'confidence': 0.33611065,\n",
       "  'topleft': {'x': 519, 'y': 269},\n",
       "  'bottomright': {'x': 691, 'y': 399}},\n",
       " {'label': 'suitcase',\n",
       "  'confidence': 0.14177082,\n",
       "  'topleft': {'x': 212, 'y': 172},\n",
       "  'bottomright': {'x': 283, 'y': 229}},\n",
       " {'label': 'chair',\n",
       "  'confidence': 0.1019164,\n",
       "  'topleft': {'x': 260, 'y': 81},\n",
       "  'bottomright': {'x': 281, 'y': 108}},\n",
       " {'label': 'laptop',\n",
       "  'confidence': 0.1288509,\n",
       "  'topleft': {'x': 98, 'y': 113},\n",
       "  'bottomright': {'x': 169, 'y': 163}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "\n",
    "#out = cv2.VideoWriter('./sample_video/output.avi',fourcc, 20.0, (int(width), int(height)))\n",
    "\n",
    "img1=cv2.imread('gun.jpg')\n",
    "\n",
    "print(np.asarray(img1).shape)\n",
    "#img2=cv2.resize(img1, (152,152))\n",
    "img=np.asarray(img1)\n",
    "print(img.shape)\n",
    "results = tfnet.return_predict(img)\n",
    "\n",
    "new_frame = boxing(img, results)\n",
    "print(new_frame.shape)\n",
    "#cv2.imshow('dwd',new_frame)\n",
    "#out.write(new_frame)\n",
    "\n",
    "#cv2.imshow('frame',new_frame)\n",
    "#out.write(img)\n",
    "cv2.imshow('frame',new_frame)\n",
    "cv2.waitKey(0); \n",
    "cv2.destroyAllWindows(); \n",
    "cv2.waitKey(1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESS = True\n",
    "\n",
    "# Definitions\n",
    "\n",
    "# Protocol Header Format\n",
    "# Cookie VersionMajor VersionMinor FrameType Timestamp ImageWidth\n",
    "# ImageHeight PixelStride RowStride\n",
    "SENSOR_STREAM_HEADER_FORMAT = \"@IBBHqIIII\"\n",
    "\n",
    "SENSOR_FRAME_STREAM_HEADER = namedtuple(\n",
    "    'SensorFrameStreamHeader',\n",
    "    'Cookie VersionMajor VersionMinor FrameType Timestamp ImageWidth ImageHeight PixelStride RowStride'\n",
    ")\n",
    "\n",
    "# Each port corresponds to a single stream type\n",
    "# Port for obtaining Photo Video Camera stream\n",
    "PV_STREAM_PORT = 23940\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    \"\"\"Receiver main\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    required_named_group = parser.add_argument_group('named arguments')\n",
    "\n",
    "    required_named_group.add_argument(\"-a\", \"--host\",\n",
    "                                      help=\"Host address to connect\", required=True)\n",
    "    args = parser.parse_args(argv)\n",
    "\n",
    "    # Create a TCP Stream socket\n",
    "    try:\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    except (socket.error, msg):\n",
    "        print(\"ERROR: Failed to create socket. Code: \" + str(msg[0]) + ', Message: ' + msg[1])\n",
    "        sys.exit()\n",
    "\n",
    "    print('INFO: socket created')\n",
    "\n",
    "    # Try connecting to the address\n",
    "    s.connect((args.host, PV_STREAM_PORT))\n",
    "\n",
    "    print('INFO: Socket Connected to ' + args.host + ' on port ' + str(PV_STREAM_PORT))\n",
    "\n",
    "    # Try receive data\n",
    "    try:\n",
    "        quit = False\n",
    "        while not quit:\n",
    "            reply = s.recv(struct.calcsize(SENSOR_STREAM_HEADER_FORMAT))\n",
    "            if not reply:\n",
    "                print('ERROR: Failed to receive data')\n",
    "                sys.exit()\n",
    "\n",
    "            data = struct.unpack(SENSOR_STREAM_HEADER_FORMAT, reply)\n",
    "\n",
    "            # Parse the header\n",
    "            header = SENSOR_FRAME_STREAM_HEADER(*data)\n",
    "\n",
    "            # read the image in chunks\n",
    "            image_size_bytes = header.ImageHeight * header.RowStride\n",
    "            image_data = ''\n",
    "\n",
    "            while len(image_data) < image_size_bytes:\n",
    "                remaining_bytes = image_size_bytes - len(image_data)\n",
    "                image_data_chunk = s.recv(remaining_bytes)\n",
    "                if not image_data_chunk:\n",
    "                    print('ERROR: Failed to receive image data')\n",
    "                    sys.exit()\n",
    "                image_data += image_data_chunk\n",
    "\n",
    "            image_array = np.frombuffer(image_data, dtype=np.uint8).reshape((header.ImageHeight,\n",
    "                                        header.ImageWidth, header.PixelStride))\n",
    "            if PROCESS:\n",
    "                # process image\n",
    "                #gray = cv2.cvtColor(image_array,cv2.COLOR_BGR2GRAY)\n",
    "                #image_array = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "                results = tfnet.return_predict(image_array)\n",
    "                new_frame = boxing(img, results)\n",
    "                #cv2.imshow('frame',new_frame)\n",
    "                #cv2.waitKey(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "            cv2.imshow('Photo Video Camera Stream', new_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    s.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n",
    "    #main(192.168.100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import darkflow\n",
    "from darkflow.net.build import TFNet\n",
    "\n",
    "import argparse\n",
    "import socket\n",
    "import sys\n",
    "import binascii\n",
    "import struct\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "options = {\"model\": \"cfg/yolo.cfg\", \n",
    "           \"load\": \"bin/yolo.weights\", \n",
    "           \"threshold\": 0.1, \n",
    "           \"gpu\": 1.0}\n",
    "\n",
    "tfnet = TFNet(options)\n",
    "def boxing(original_img, predictions):\n",
    "    newImage = np.copy(original_img)\n",
    "\n",
    "    for result in predictions:\n",
    "        top_x = result['topleft']['x']\n",
    "        top_y = result['topleft']['y']\n",
    "\n",
    "        btm_x = result['bottomright']['x']\n",
    "        btm_y = result['bottomright']['y']\n",
    "\n",
    "        confidence = result['confidence']\n",
    "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
    "\n",
    "        if confidence > 0.3:\n",
    "            newImage = cv2.rectangle(newImage, (top_x, top_y), (btm_x, btm_y), (255,0,0), 3)\n",
    "            newImage = cv2.putText(newImage, label, (top_x, top_y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL , 0.8, (0, 230, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "    return newImage\n",
    "\n",
    "PROCESS = True\n",
    "\n",
    "# Definitions\n",
    "\n",
    "# Protocol Header Format\n",
    "# Cookie VersionMajor VersionMinor FrameType Timestamp ImageWidth\n",
    "# ImageHeight PixelStride RowStride\n",
    "SENSOR_STREAM_HEADER_FORMAT = \"@IBBHqIIII\"\n",
    "\n",
    "SENSOR_FRAME_STREAM_HEADER = namedtuple(\n",
    "    'SensorFrameStreamHeader',\n",
    "    'Cookie VersionMajor VersionMinor FrameType Timestamp ImageWidth ImageHeight PixelStride RowStride'\n",
    ")\n",
    "\n",
    "# Each port corresponds to a single stream type\n",
    "# Port for obtaining Photo Video Camera stream\n",
    "PV_STREAM_PORT = 23940\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    \"\"\"Receiver main\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    required_named_group = parser.add_argument_group('named arguments')\n",
    "\n",
    "    required_named_group.add_argument(\"-a\", \"--host\",\n",
    "                                      help=\"Host address to connect\", required=True)\n",
    "    args = parser.parse_args(argv)\n",
    "\n",
    "    # Create a TCP Stream socket\n",
    "    try:\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    except (socket.error, msg):\n",
    "        print(\"ERROR: Failed to create socket. Code: \" + str(msg[0]) + ', Message: ' + msg[1])\n",
    "        sys.exit()\n",
    "\n",
    "    print('INFO: socket created')\n",
    "\n",
    "    # Try connecting to the address\n",
    "    s.connect((args.host, PV_STREAM_PORT))\n",
    "\n",
    "    print('INFO: Socket Connected to ' + args.host + ' on port ' + str(PV_STREAM_PORT))\n",
    "\n",
    "    # Try receive data\n",
    "    try:\n",
    "        quit = False\n",
    "        while not quit:\n",
    "            reply = s.recv(struct.calcsize(SENSOR_STREAM_HEADER_FORMAT))\n",
    "            if not reply:\n",
    "                print('ERROR: Failed to receive data')\n",
    "                sys.exit()\n",
    "\n",
    "            data = struct.unpack(SENSOR_STREAM_HEADER_FORMAT, reply)\n",
    "\n",
    "            # Parse the header\n",
    "            header = SENSOR_FRAME_STREAM_HEADER(*data)\n",
    "\n",
    "            # read the image in chunks\n",
    "            image_size_bytes = header.ImageHeight * header.RowStride\n",
    "            image_data = bytes()\n",
    "            print(\"Data Receiver ______________\")\n",
    "            while len(image_data) < image_size_bytes:\n",
    "                remaining_bytes = image_size_bytes - len(image_data)\n",
    "                image_data_chunk = s.recv(remaining_bytes)\n",
    "                if not image_data_chunk:\n",
    "                    print('ERROR: Failed to receive image data')\n",
    "                    sys.exit()\n",
    "                image_data += image_data_chunk\n",
    "\n",
    "            image_array = np.frombuffer(image_data, dtype=np.uint8).reshape((header.ImageHeight,\n",
    "                                        header.ImageWidth, header.PixelStride))\n",
    "            if PROCESS:\n",
    "                # process image\n",
    "                #gray = cv2.cvtColor(image_array,cv2.COLOR_BGR2GRAY)\n",
    "                #image_array = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "                image_array=image_array[:,:,:3]\n",
    "                image_array=cv2.resize(image_array, (320,180))\n",
    "                print(\"going to resuklts\",image_array.shape)\n",
    "                results = tfnet.return_predict(image_array[:,:,:3])\n",
    "                new_frame = boxing(image_array[:,:,:3], results)\n",
    "                #cv2.imshow('frame',new_frame)\n",
    "                #cv2.waitKey(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "            cv2.imshow('Photo Video Camera Stream', new_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    s.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n",
    "    #main(192.168.100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
